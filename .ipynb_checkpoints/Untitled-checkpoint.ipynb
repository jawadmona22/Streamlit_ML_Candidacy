{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4c5812a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold,GridSearchCV,GroupShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import  ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.calibration import calibration_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c71842e",
   "metadata": {},
   "source": [
    "## Processing Functions ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "687eac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean_Data(debug=False,all_labels=[]): #This function extracts the columns of interest, removes NA, and adds patient ID\n",
    "    full_dataset = pd.read_csv(\"Candidacy-Streamlit-Repo/candidacy_v3.csv\")\n",
    "\n",
    "    if 'Age' in full_dataset.columns:\n",
    "        # Calculate median age (ignores NaNs by default)\n",
    "        median_age = full_dataset[\"Age\"].median()\n",
    "        print(\"Missing before:\", full_dataset[\"Age\"].isna().sum())\n",
    "        full_dataset[\"Age\"].fillna(median_age, inplace=True)\n",
    "        print(\"Missing after:\", full_dataset[\"Age\"].isna().sum())\n",
    "\n",
    "    if 'HLdur_R' and 'HLdur_L' in full_dataset.columns:\n",
    "\n",
    "        #First for right\n",
    "        median_hl_r = full_dataset[\"HLdur_R\"].median()\n",
    "        full_dataset[\"HLdur_R\"].fillna(median_hl_r, inplace=True)\n",
    "        #Then for L\n",
    "        median_hl_l = full_dataset[\"HLdur_L\"].median()\n",
    "        full_dataset[\"HLdur_L\"].fillna(median_hl_l, inplace=True)\n",
    "\n",
    "    if 'Hearing_Aid_Use_Time_R' and 'Hearing_Aid_Use_Time_L' in full_dataset.columns:\n",
    "        # First for right\n",
    "        median_ha_r = full_dataset[\"Hearing_Aid_Use_Time_R\"].median()\n",
    "        full_dataset[\"Hearing_Aid_Use_Time_R\"].fillna(median_ha_r, inplace=True)\n",
    "        # Then for L\n",
    "        median_ha_l = full_dataset[\"Hearing_Aid_Use_Time_L\"].median()\n",
    "        full_dataset[\"Hearing_Aid_Use_Time_L\"].fillna(median_ha_l, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    #Need to keep everything together to prevent loss of data\n",
    "    filtered_dataset = full_dataset[all_labels].dropna()\n",
    "    filtered_dataset['patient_id'] = range(1, len(filtered_dataset) + 1)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Filtered Dataset: {filtered_dataset.head}\")\n",
    "        print(f\"Filtered Columns: {filtered_dataset.columns}\")\n",
    "\n",
    "\n",
    "    return filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6e54a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Left_Right_Data(unseparated_data,debug=False):\n",
    "#Data from L/R is combined so that they are unlabeled, but patient IDs are preserved'''\n",
    "\n",
    "    df = pd.DataFrame(unseparated_data)\n",
    "    # Separate L and R columns\n",
    "    left_df = df.filter(regex='_L$').copy()\n",
    "    right_df = df.filter(regex='_R$').copy()\n",
    "\n",
    "    # Extract the patient_id column\n",
    "    patient_ids = df['patient_id'].copy()\n",
    "    if 'Age' in df.columns:\n",
    "        ages = df['Age'].copy()\n",
    "\n",
    "# Rename columns by removing the side-specific suffix\n",
    "    left_df.columns = left_df.columns.str.replace('_L$', '', regex=True)\n",
    "    right_df.columns = right_df.columns.str.replace('_R$', '', regex=True)\n",
    "\n",
    "    # Concatenate the dataframes\n",
    "    left_df['patient_id'] = patient_ids\n",
    "    right_df['patient_id'] = patient_ids\n",
    "\n",
    "    #Add in age as well\n",
    "    if 'Age' in df.columns:\n",
    "        left_df['Age'] = ages\n",
    "        right_df['Age'] = ages\n",
    "    left_right_data = pd.concat([left_df, right_df], ignore_index=True)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Data split into l/r data columns: {left_right_data.head}\")\n",
    "        if left_right_data.shape[0] != (df.shape[0] * 2):\n",
    "            #We should be doubling the patient data\n",
    "            print(\"WARNING! Shape is not correct for L/R Data\")\n",
    "        patient1_data = left_right_data[left_right_data['patient_id']==1]\n",
    "        print(patient1_data)\n",
    "    return left_right_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5412c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add_Categorical_Bins(left_right_data,num_bins,debug):\n",
    "    #E.G The 25th percentile means 25% of the data is less than or equal to that value.\n",
    "    percentiles = np.linspace(0,100,num_bins+2)\n",
    "    binned_data = left_right_data.copy()\n",
    "    thresholds = np.unique(np.percentile(left_right_data['CNC'],percentiles))\n",
    "    binned_data['CNC_bin'] = np.digitize(left_right_data['CNC'], thresholds, right=True)\n",
    "    # Identify bin threshold below 50\n",
    "    fifty_threshold = max(i for i, upper in enumerate(thresholds) if upper < 50)\n",
    "    if debug:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(binned_data['CNC'], bins=thresholds, edgecolor='black', alpha=0.7)\n",
    "        plt.axvline(x=thresholds[fifty_threshold], color='red', linestyle='--', label='CNC 50 Cutoff')\n",
    "        plt.legend()\n",
    "        plt.plot()\n",
    "        plt.title('Distribution of CNC Bins (Percentile-based)')\n",
    "        plt.xlabel('CNC Score')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.xticks(rotation=45, fontsize=8)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.show()\n",
    "        print(f\"Percentiles: {percentiles}\")\n",
    "        print(f\"Thresholds {thresholds}\")\n",
    "        print(f\"Threshold for CNC 50 is bin {fifty_threshold}\")\n",
    "        print(f\"Data Bins:{binned_data['CNC_bin'] }\")\n",
    "        print(f\"CNC for Bin 1: {binned_data[binned_data['CNC_bin']==1]['CNC']}\")\n",
    "    return binned_data, fifty_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14ae64cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Test_Split(binned_data,debug=False,raw=False):\n",
    "    if raw == False:\n",
    "        X = binned_data.drop(columns=['CNC_bin', 'CNC', 'patient_id'])\n",
    "        y = binned_data['CNC_bin']\n",
    "        groups = binned_data['patient_id'].values\n",
    "        # Train-test split\n",
    "        splitter = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=42)\n",
    "        train_idx, test_idx = next(splitter.split(X, y, groups=groups))\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        groups_train = groups[train_idx]  # Extract corresponding train groups\n",
    "\n",
    "        if debug:\n",
    "            print(f\"Columns in X_Train: {X_train.columns}\")\n",
    "            print(f\"Columns in X_Test: {X_test.columns}\")\n",
    "\n",
    "        return X_train,X_test,y_train,y_test, groups_train\n",
    "    else:\n",
    "        X = binned_data.drop(columns=['CNC', 'patient_id'])\n",
    "        y = binned_data['CNC']\n",
    "        groups = binned_data['patient_id'].values\n",
    "        # Train-test split\n",
    "        splitter = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=42)\n",
    "        train_idx, test_idx = next(splitter.split(X, y, groups=groups))\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        groups_train = groups[train_idx]  # Extract corresponding train groups\n",
    "\n",
    "        if debug:\n",
    "            print(f\"Columns in X_Train: {X_train.columns}\")\n",
    "            print(f\"Columns in X_Test: {X_test.columns}\")\n",
    "\n",
    "        return X_train, X_test, y_train, y_test, groups_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6af4cf",
   "metadata": {},
   "source": [
    "## Model Functions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4fe70680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Optimize_Model(X_train,y_train,groups_train,debug=False,raw=False,soft_label=False,pkl_name = 'grid_search'):\n",
    "    '''This section will take the selected model in 'params' and train the model'''\n",
    "\n",
    "    kf = GroupKFold(n_splits=10)\n",
    "\n",
    "\n",
    "    if raw == True:\n",
    "        # Define parameter grids\n",
    "        pipeline = Pipeline([\n",
    "            ('regressor', RandomForestRegressor())  # Placeholder\n",
    "        ])\n",
    "        param_grid = [\n",
    "            {  # Random Forest Regressor\n",
    "                'regressor': [RandomForestRegressor(random_state=42)],\n",
    "                'regressor__n_estimators': [50, 100, 200],\n",
    "                'regressor__max_depth': [10, 20, None],\n",
    "                'regressor__min_samples_split': [2, 5, 10]\n",
    "            },\n",
    "            {  # XGBoost Regressor\n",
    "                'regressor': [XGBRegressor(objective='reg:squarederror', random_state=42)],\n",
    "                'regressor__n_estimators': [50, 100, 200],\n",
    "                'regressor__max_depth': [3, 6, 10],\n",
    "                'regressor__learning_rate': [0.01, 0.1, 0.2]\n",
    "            },\n",
    "            {  # Vanilla Linear Regression (no tuning)\n",
    "                'regressor': [LinearRegression()]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Set up GridSearchCV\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=param_grid,\n",
    "            scoring='neg_mean_squared_error',  # works for both regressors and log-loss classifiers\n",
    "            cv=kf,\n",
    "            n_jobs=-1,\n",
    "            verbose=3\n",
    "        )\n",
    "\n",
    "        grid_search.fit(X_train, y_train, groups=groups_train)\n",
    "\n",
    "        with open(f'{pkl_name}.pkl', 'wb') as f:\n",
    "            pickle.dump(grid_search, f)\n",
    "\n",
    "\n",
    "        return grid_search\n",
    "\n",
    "    if raw == False: #Case: classification problem\n",
    "        pipeline = Pipeline([\n",
    "            ('classifier', RandomForestClassifier(random_state=42))  # Placeholder, will be overridden\n",
    "        ])\n",
    "        # Define parameter grids for different classifiers\n",
    "        param_grid = [\n",
    "            {  # Random Forest\n",
    "                'classifier': [RandomForestClassifier(random_state=42)],\n",
    "                'classifier__n_estimators': [50, 100, 200],\n",
    "                'classifier__max_depth': [10, 20, None],\n",
    "                'classifier__min_samples_split': [2, 5, 10]\n",
    "            },\n",
    "            {  # XGBoost\n",
    "                'classifier': [XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)],\n",
    "                'classifier__n_estimators': [50, 100, 200],\n",
    "                'classifier__max_depth': [3, 6, 10],\n",
    "                'classifier__learning_rate': [0.01, 0.1, 0.2]\n",
    "            },\n",
    "            # {  # Logistic Regression\n",
    "            #     'classifier': [LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)],\n",
    "            #     'classifier__C': [0.01, 0.1, 1, 10],\n",
    "            #     'classifier__penalty': ['l2']\n",
    "            # },\n",
    "            {  # Vanilla Logistic Regression (no hyperparameter tuning)\n",
    "                'classifier': [LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)]\n",
    "                # No hyperparameters specified\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Perform GridSearchCV with GroupKFold\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=param_grid,\n",
    "            scoring='f1_micro',\n",
    "            cv=kf,\n",
    "            n_jobs=-1,\n",
    "            verbose=3\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train, groups=groups_train)\n",
    "        with open(f'{pkl_name}', 'wb') as f:\n",
    "            pickle.dump(grid_search, f)\n",
    "\n",
    "        if debug:\n",
    "\n",
    "            y_pred = grid_search.best_estimator_.predict(X_train)\n",
    "            # Extract the classifier name from the pipeline\n",
    "            model_name = grid_search.best_estimator_.named_steps['classifier'].__class__.__name__\n",
    "\n",
    "            # Plot confusion matrix\n",
    "            fig, ax = plt.subplots(figsize=(6, 5))\n",
    "            ConfusionMatrixDisplay.from_predictions(y_train, y_pred, ax=ax)\n",
    "            ax.set_title(f\"Training Data Confusion Matrix {model_name}\")\n",
    "            plt.show()\n",
    "        return grid_search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7409afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_roc_auc(y_true, y_score, n_bootstraps=1000, random_state=42):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    tprs = []\n",
    "    base_fpr = np.linspace(0, 1, 101)\n",
    "    y_true = np.array(y_true)\n",
    "    y_score = np.array(y_score)\n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = rng.choice(len(y_true), size=len(y_true), replace=True)\n",
    "        # if len(np.unique(y_true[indices])) < 2:\n",
    "        #     continue  # skip if only one class present\n",
    "        fpr, tpr, _ = roc_curve(y_true[indices], y_score[indices])\n",
    "        tpr_interp = np.interp(base_fpr, fpr, tpr)\n",
    "        tpr_interp[0] = 0.0\n",
    "        tprs.append(tpr_interp)\n",
    "\n",
    "    tprs = np.array(tprs)\n",
    "    mean_tpr = tprs.mean(axis=0)\n",
    "    std_tpr = tprs.std(axis=0)\n",
    "    tprs_lower = np.clip(mean_tpr - 1.96 * std_tpr, 0, 1)\n",
    "    print(tprs_lower)\n",
    "    tprs_upper = np.clip(mean_tpr + 1.96 * std_tpr, 0, 1)\n",
    "\n",
    "    return base_fpr, mean_tpr, tprs_lower, tprs_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "269080a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_visualizations(grid_search,X_test,y_test,bin_threshold,raw=False,label='Default'):\n",
    "    if raw == False:\n",
    "        best_models = {}\n",
    "        model_performance = []\n",
    "\n",
    "\n",
    "\n",
    "        for i, param in enumerate(grid_search.cv_results_['params']):\n",
    "            model_name = param['classifier'].__class__.__name__\n",
    "            mean_score = grid_search.cv_results_['mean_test_score'][i]\n",
    "\n",
    "            # Only store the best param set per model\n",
    "            if model_name not in best_models or mean_score > best_models[model_name]['score']:\n",
    "                best_models[model_name] = {\n",
    "                    'params': param,\n",
    "                    'score': mean_score\n",
    "                }\n",
    "\n",
    "        # Refit the best model for each model type\n",
    "        for model_name in best_models:\n",
    "            best_param = best_models[model_name]['params']\n",
    "            model_pipeline = grid_search.estimator.set_params(**best_param)\n",
    "            model_pipeline.fit(X_test, y_test)\n",
    "            classifier = model_pipeline.named_steps['classifier']\n",
    "            best_models[model_name]['model'] = classifier  # Store fitted classifier\n",
    "\n",
    "        for model_name, model_info in best_models.items():\n",
    "            best_model = model_info['model']\n",
    "            print(f\"Running model: {model_name}\")\n",
    "            y_true_binary = (y_test <= bin_threshold).astype(int)\n",
    "            y_pred_prob = best_model.predict_proba(X_test)  #Outputs an array of probabilities for each test data corresponding to the ten categories\n",
    "            # Classes to sum for binary prob\n",
    "            pred_prob_below_thresh = y_pred_prob[:, :bin_threshold].sum(axis=1)\n",
    "            y_pred_prob_binary = (pred_prob_below_thresh >= 0.5).astype(int) #We classify as \"1\" if your probability is >=.5\n",
    "            # Compute ROC curve and AUC\n",
    "            fpr, tpr, _ = roc_curve(y_true_binary, y_pred_prob_binary)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.close('all')\n",
    "            plt.figure()\n",
    "            # Plot the ROC curve\n",
    "            plt.plot(fpr, tpr, label=f\"{model_name} (AUC = {roc_auc:.3f})\")\n",
    "            plt.xlabel(\"False Positive Rate\")\n",
    "            plt.ylabel(\"True Positive Rate\")\n",
    "            plt.title(f\"ROC AUC Curve (Threshold = {bin_threshold})\")\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"{label}-AUC.png\")\n",
    "\n",
    "            # Bootstrap ROC and get confidence bounds\n",
    "            fpr,tpr, tpr_lower, tpr_upper = bootstrap_roc_auc(\n",
    "                y_true_binary, y_pred_prob_binary\n",
    "            )\n",
    "            # Compute AUC for the lower bound of the TPR\n",
    "            auc_lower_bound = auc(fpr, tpr_lower)\n",
    "\n",
    "            # Compute AUC for the upper bound of the TPR\n",
    "            auc_upper_bound = auc(fpr, tpr_upper)\n",
    "\n",
    "\n",
    "            tn,fp,fn,tp = confusion_matrix(y_true_binary,y_pred_prob_binary).ravel() #Ravel flattens this into a 1d Array so we can assign the variables\n",
    "            sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0  # same as recall\n",
    "            specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "            precision = precision_score(y_true_binary, y_pred_prob_binary, zero_division=0)\n",
    "            recall = recall_score(y_true_binary, y_pred_prob_binary, zero_division=0)\n",
    "            f1 = f1_score(y_true_binary, y_pred_prob_binary, zero_division=0)\n",
    "\n",
    "\n",
    "            # roc_auc = auc(fpr, mean_tpr)\n",
    "            # plt.plot(fpr, mean_tpr, label=f\"{model_name} (AUC = {roc_auc:.3f})\")\n",
    "            plt.fill_between(fpr, tpr_lower, tpr_upper, alpha=0.2)\n",
    "            model_performance.append({\n",
    "                'Model': model_name,\n",
    "                'AUC': roc_auc,\n",
    "                'CI Lower Bound': auc_lower_bound,\n",
    "                'CI Upper Bound': auc_upper_bound,\n",
    "                'Sensitivity': sensitivity,\n",
    "                'Specificity': specificity,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'F1 Score': f1\n",
    "            })\n",
    "\n",
    "        # Final plot settings\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC AUC Curve with 95% CI\")\n",
    "        plt.legend()\n",
    "        plt.plot([0, 1], [0, 1], 'k--', label=\"Chance (AUC = 0.5)\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        performance_df = pd.DataFrame(model_performance)\n",
    "        # Display the table of AUC and CI for each model\n",
    "        performance_df.to_excel(f\"performance-{label}.xlsx\")\n",
    "\n",
    "        ##Calibration curves\n",
    "        # plt.figure(figsize=(8, 6))\n",
    "\n",
    "        # Set up subplot grid\n",
    "        num_models = len(best_models)\n",
    "        ncols = 2\n",
    "        nrows = (num_models + 1) // ncols  # Round up for uneven count\n",
    "        fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 4 * nrows))\n",
    "        axes = axes.flatten()  # Flatten to index easily\n",
    "\n",
    "        for idx, (model_name, model_info) in enumerate(best_models.items()):\n",
    "            ax = axes[idx]\n",
    "            best_model = model_info['model']\n",
    "            print(f\"Running model: {model_name}\")\n",
    "\n",
    "            y_true_binary = (y_test <= bin_threshold).astype(int)\n",
    "            y_pred_prob = best_model.predict_proba(X_test)\n",
    "            pred_prob_below_thresh = y_pred_prob[:, :bin_threshold].sum(axis=1)\n",
    "\n",
    "            fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "                y_true_binary, pred_prob_below_thresh, n_bins=10\n",
    "            )\n",
    "\n",
    "            # Plot calibration curve\n",
    "            ax.plot(mean_predicted_value, fraction_of_positives, marker='o', label='Calibration Curve')\n",
    "\n",
    "            # Plot histogram for RandomForest\n",
    "            # if \"Random\" in model_name:\n",
    "            counts, bins = np.histogram(pred_prob_below_thresh, bins=10, range=(0, 1))\n",
    "            proportions = counts / counts.sum()\n",
    "            bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "            bin_width = bins[1] - bins[0]\n",
    "            ax.bar(bin_centers, proportions, width=bin_width, alpha=0.5, label='Pred Prob Histogram')\n",
    "            ax.set_ylim(0, 1)\n",
    "\n",
    "            # Perfect calibration line\n",
    "            ax.plot([0, 1], [0, 1], 'k--', label='Perfectly Calibrated')\n",
    "\n",
    "            ax.set_title(f\"{model_name} Calibration\")\n",
    "            ax.set_xlabel(\"Mean Predicted Probability\")\n",
    "            ax.set_ylabel(\"Fraction of Positives\")\n",
    "            # ax.legend(loc='best')\n",
    "            ax.grid(True)\n",
    "\n",
    "        # Hide any unused subplots\n",
    "        for j in range(idx + 1, len(axes)):\n",
    "            fig.delaxes(axes[j])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c48c69",
   "metadata": {},
   "source": [
    "## Main ML Pipeline Call ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1390fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_ml_call(num_bins = 10, smote = False, method = \"ML\",raw=False,is_soft_label = False,all_labels = [],label = 'default'):\n",
    "\n",
    "    #Extract columns of interest, remove NA, and add patient ID and CNC bin\n",
    "    filtered_dataset = Clean_Data(debug=False,all_labels=all_labels)\n",
    "    left_right_data = Create_Left_Right_Data(filtered_dataset,debug=False)\n",
    "    \n",
    "    ##Case 1: No bins\n",
    "    if raw == True:\n",
    "        X_train, X_test, y_train,y_test,groups_train = Train_Test_Split(left_right_data, debug=False,raw=True)\n",
    "        if method == \"ML\":\n",
    "            #Run grid search on the split data **for regressor**\n",
    "\n",
    "            if is_soft_label:\n",
    "                y_train_soft = soft_label(y_train)\n",
    "                x = np.linspace(0,1,len(y_train_soft))\n",
    "                plt.scatter(x,y_train_soft)\n",
    "                plt.show()\n",
    "                y_test_soft = soft_label(y_test)\n",
    "\n",
    "                # # Hard binary label for evaluation only\n",
    "                # y_train_binary = (y_train <= 40).astype(int)\n",
    "                # y_test_binary = (y_test <= 40).astype(int)\n",
    "                grid_search = Optimize_Model(X_train, y_train_soft, groups_train, debug=True, raw=True,soft_label=is_soft_label,pkl_name=label)\n",
    "\n",
    "            else:\n",
    "                # grid_search = Optimize_Model(X_train, y_train, groups_train, debug=True, raw=True)\n",
    "\n",
    "                with open(f'{label}.pkl', 'rb') as f:\n",
    "                    grid_search = pickle.load(f)\n",
    "\n",
    "                #Make y_train and y_test binary now\n",
    "                y_train_binary = (y_train <=40).astype(int) #A series of 0/1\n",
    "                y_test_binary = (y_test <=40).astype(int)\n",
    "\n",
    "                best_model = grid_search.best_estimator_\n",
    "                print(best_model)\n",
    "                y_pred = best_model.predict(X_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # run_visualizations(grid_search, X_test, y_test,bin_threshold=fifty_threshold)\n",
    "\n",
    "            #\n",
    "            # y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "            # model_name = grid_search.best_estimator_.named_steps['classifier'].__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    if raw == False:\n",
    "        binned_data,fifty_threshold = Add_Categorical_Bins(left_right_data,num_bins=10,debug=False)\n",
    "\n",
    "    # Split into train/test while preserving which patient is in each group\n",
    "        X_train, X_test, y_train,y_test,groups_train = Train_Test_Split(binned_data, debug=False,raw=False)\n",
    "\n",
    "        if smote:\n",
    "            #Equal *spaced* bins with SMOTE applied\n",
    "            smote = SMOTE(sampling_strategy=\"auto\", random_state=42)\n",
    "            X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "            plt.hist(y_train_resampled, edgecolor='black', alpha=0.7)\n",
    "            # Extend `groups_train` to match SMOTE's new sample count\n",
    "            num_new_samples = len(X_train_resampled) - len(X_train)\n",
    "            # Assign synthetic samples a placeholder group (-1)\n",
    "            groups_resampled = np.concatenate([groups_train, np.full(num_new_samples, -1)])\n",
    "            X_train, y_train, groups_train = X_train_resampled, y_train_resampled, groups_resampled\n",
    "\n",
    "        if method == \"ML\":\n",
    "            #Run grid search on the split data **for multicategorical classifier**\n",
    "            grid_search = Optimize_Model(X_train,y_train,groups_train,debug=True)\n",
    "            # with open('best_grid_search_10_bins_smote.pkl', 'rb') as f:\n",
    "            #     grid_search = pickle.load(f)\n",
    "\n",
    "\n",
    "            #Sanity check our best model with a confusion matrix on X_test\n",
    "            y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "            model_name = grid_search.best_estimator_.named_steps['classifier'].__class__.__name__\n",
    "            fig, ax = plt.subplots(figsize=(6, 5))\n",
    "            ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax)\n",
    "            ax.set_title(f\"Best Model ({model_name}) on Test Data for {label}\")\n",
    "            plt.savefig(f\"cm-{label}\")\n",
    "            # plt.show()\n",
    "\n",
    "            run_visualizations(grid_search, X_test, y_test,bin_threshold=fifty_threshold,label=label)\n",
    "        if method == \"60/60\":\n",
    "            # Get predictions\n",
    "            y_pred = sixty_sixty_predictions(X_test)\n",
    "            y_true_binary = (y_test <= 5).astype(int)\n",
    "\n",
    "\n",
    "#             Confusion Matrix\n",
    "            conf_matrix = confusion_matrix(y_true_binary, y_pred)\n",
    "\n",
    "            #Plot confusion matrix\n",
    "            plt.figure(figsize=(6, 5))\n",
    "            sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "                        xticklabels=[\"Predicted Non-Candidate\", \"Predicted Candidate\"],\n",
    "                        yticklabels=[\"Actual Non-Candidate\", \"Actual Candidate\"])\n",
    "            plt.xlabel(\"Prediction\")\n",
    "            plt.ylabel(\"Actual\")\n",
    "            plt.title(\"Confusion Matrix for 60/60 Rule\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            y_true_binary = y_true_binary.values.tolist()\n",
    "\n",
    "            precision = precision_score(y_true_binary, y_pred, zero_division=0)\n",
    "            recall = recall_score(y_true_binary, y_pred, zero_division=0)\n",
    "            f1 = f1_score(y_true_binary, y_pred, zero_division=0)\n",
    "            accuracy = accuracy_score(y_true_binary, y_pred)\n",
    "            print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {recall}\")\n",
    "            return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0108f2a5",
   "metadata": {},
   "source": [
    "## 60/60 Rule Figures ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d657734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sixty_sixty_predictions(X_test):\n",
    "    y_pred = []\n",
    "\n",
    "    for index, row in X_test.iterrows():\n",
    "        hz_500 = row[\"hz500\"]\n",
    "        hz_1000 = row[\"hz1000\"]\n",
    "        hz_2000 = row[\"hz2000\"]\n",
    "        wrs = row[\"WRS\"]\n",
    "\n",
    "        if hz_500 >= 60 and hz_1000 >= 60 and hz_2000 >= 60 and wrs < 60:\n",
    "            y_pred.append(1) #They are a candidate\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "69067ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sixty_sixty_run():\n",
    "    all_labels = [\n",
    "        'hz125_R', 'hz125_L', 'hz250_R', 'hz250_L',\n",
    "        'hz500_R', 'hz500_L', 'hz750_R', 'hz750_L',\n",
    "        'hz1000_R', 'hz1000_L', 'hz1500_R', 'hz1500_L',\n",
    "        'hz2000_R', 'hz2000_L', 'hz3000_R', 'hz3000_L',\n",
    "        'hz4000_R', 'hz4000_L', 'hz6000_R', 'hz6000_L', 'hz8000_R', 'hz8000_L',\n",
    "        'WRS_L', 'WRS_R', 'Age', 'CNC_L', 'CNC_R'\n",
    "    ]\n",
    "\n",
    "    accuracy, precision, recall, f1 = main_ml_call(method=\"60/60\",label=\"sixty\",all_labels=all_labels)\n",
    "    return accuracy, precision, recall, f1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f6cae04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing before: 83\n",
      "Missing after: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6919431279620853, Precision: 0.7828282828282829, Recall: 0.640495867768595, F1: 0.640495867768595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6919431279620853, 0.7828282828282829, 0.640495867768595, 0.7045454545454546)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sixty_sixty_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c3509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
