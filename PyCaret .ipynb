{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e85b6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold,GridSearchCV,GroupShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import  ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.calibration import calibration_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from pycaret.classification import setup, compare_models, tune_model, predict_model, save_model, evaluate_model\n",
    "from sklearn.model_selection import GroupKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5daffe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def Clean_Data(debug=False,all_labels=[]): #This function extracts the columns of interest, removes NA, and adds patient ID\n",
    "    full_dataset = pd.read_csv(\"Candidacy-Streamlit-Repo/candidacy_v3.csv\")\n",
    "\n",
    "    if 'Age' in full_dataset.columns:\n",
    "        # Calculate median age (ignores NaNs by default)\n",
    "        median_age = full_dataset[\"Age\"].median()\n",
    "        print(\"Missing before:\", full_dataset[\"Age\"].isna().sum())\n",
    "        full_dataset[\"Age\"].fillna(median_age, inplace=True)\n",
    "        print(\"Missing after:\", full_dataset[\"Age\"].isna().sum())\n",
    "\n",
    "    if 'HLdur_R' and 'HLdur_L' in full_dataset.columns:\n",
    "\n",
    "        #First for right\n",
    "        median_hl_r = full_dataset[\"HLdur_R\"].median()\n",
    "        full_dataset[\"HLdur_R\"].fillna(median_hl_r, inplace=True)\n",
    "        #Then for L\n",
    "        median_hl_l = full_dataset[\"HLdur_L\"].median()\n",
    "        full_dataset[\"HLdur_L\"].fillna(median_hl_l, inplace=True)\n",
    "\n",
    "    if 'Hearing_Aid_Use_Time_R' and 'Hearing_Aid_Use_Time_L' in full_dataset.columns:\n",
    "        # First for right\n",
    "        median_ha_r = full_dataset[\"R_Hearing_Aid_Use_Time\"].median()\n",
    "        full_dataset[\"R_Hearing_Aid_Use_Time\"].fillna(median_ha_r, inplace=True)\n",
    "        # Then for L\n",
    "        median_ha_l = full_dataset[\"L_Hearing_Aid_Use_Time\"].median()\n",
    "        full_dataset[\"L_Hearing_Aid_Use_Time\"].fillna(median_ha_l, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    #Need to keep everything together to prevent loss of data\n",
    "    filtered_dataset = full_dataset[all_labels].dropna()\n",
    "    filtered_dataset['patient_id'] = range(1, len(filtered_dataset) + 1)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Filtered Dataset: {filtered_dataset.head}\")\n",
    "        print(f\"Filtered Columns: {filtered_dataset.columns}\")\n",
    "\n",
    "\n",
    "    return filtered_dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Create_Left_Right_Data(unseparated_data,debug=False):\n",
    "#Data from L/R is combined so that they are unlabeled, but patient IDs are preserved'''\n",
    "\n",
    "    df = pd.DataFrame(unseparated_data)\n",
    "    # Separate L and R columns\n",
    "    left_df = df.filter(regex='_L$').copy()\n",
    "    right_df = df.filter(regex='_R$').copy()\n",
    "\n",
    "    # Extract the patient_id column\n",
    "    patient_ids = df['patient_id'].copy()\n",
    "    if 'Age' in df.columns:\n",
    "        ages = df['Age'].copy()\n",
    "\n",
    "# Rename columns by removing the side-specific suffix\n",
    "    left_df.columns = left_df.columns.str.replace('_L$', '', regex=True)\n",
    "    right_df.columns = right_df.columns.str.replace('_R$', '', regex=True)\n",
    "\n",
    "    # Concatenate the dataframes\n",
    "    left_df['patient_id'] = patient_ids\n",
    "    right_df['patient_id'] = patient_ids\n",
    "\n",
    "    #Add in age as well\n",
    "    if 'Age' in df.columns:\n",
    "        left_df['Age'] = ages\n",
    "        right_df['Age'] = ages\n",
    "    left_right_data = pd.concat([left_df, right_df], ignore_index=True)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Data split into l/r data columns: {left_right_data.head}\")\n",
    "        if left_right_data.shape[0] != (df.shape[0] * 2):\n",
    "            #We should be doubling the patient data\n",
    "            print(\"WARNING! Shape is not correct for L/R Data\")\n",
    "        patient1_data = left_right_data[left_right_data['patient_id']==1]\n",
    "        print(patient1_data)\n",
    "    return left_right_data\n",
    "\n",
    "def Add_Categorical_Bins(left_right_data,num_bins,debug):\n",
    "    #E.G The 25th percentile means 25% of the data is less than or equal to that value.\n",
    "    percentiles = np.linspace(0,100,num_bins+2)\n",
    "    binned_data = left_right_data.copy()\n",
    "    thresholds = np.unique(np.percentile(left_right_data['CNC'],percentiles))\n",
    "    binned_data['CNC_bin'] = np.digitize(left_right_data['CNC'], thresholds, right=True)\n",
    "    # Identify bin threshold below 50\n",
    "    fifty_threshold = max(i for i, upper in enumerate(thresholds) if upper < 50)\n",
    "    if debug:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(binned_data['CNC'], bins=thresholds, edgecolor='black', alpha=0.7)\n",
    "        plt.axvline(x=thresholds[fifty_threshold], color='red', linestyle='--', label='CNC 50 Cutoff')\n",
    "        plt.legend()\n",
    "        plt.plot()\n",
    "        plt.title('Distribution of CNC Bins (Percentile-based)')\n",
    "        plt.xlabel('CNC Score')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.xticks(rotation=45, fontsize=8)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.show()\n",
    "        print(f\"Percentiles: {percentiles}\")\n",
    "        print(f\"Thresholds {thresholds}\")\n",
    "        print(f\"Threshold for CNC 50 is bin {fifty_threshold}\")\n",
    "        print(f\"Data Bins:{binned_data['CNC_bin'] }\")\n",
    "        print(f\"CNC for Bin 1: {binned_data[binned_data['CNC_bin']==1]['CNC']}\")\n",
    "    return binned_data, fifty_threshold\n",
    "\n",
    "\n",
    "def Train_Test_Split(binned_data,debug=False,raw=False):\n",
    "    if raw == False:\n",
    "        X = binned_data.drop(columns=['CNC_bin', 'CNC', 'patient_id'])\n",
    "        y = binned_data['CNC_bin']\n",
    "        groups = binned_data['patient_id'].values\n",
    "        # Train-test split\n",
    "        splitter = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=42)\n",
    "        train_idx, test_idx = next(splitter.split(X, y, groups=groups))\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        groups_train = groups[train_idx]  # Extract corresponding train groups\n",
    "\n",
    "        if debug:\n",
    "            print(f\"Columns in X_Train: {X_train.columns}\")\n",
    "            print(f\"Columns in X_Test: {X_test.columns}\")\n",
    "\n",
    "        return X_train,X_test,y_train,y_test, groups_train\n",
    "    else:\n",
    "        X = binned_data.drop(columns=['CNC', 'patient_id'])\n",
    "        y = binned_data['CNC']\n",
    "        groups = binned_data['patient_id'].values\n",
    "        # Train-test split\n",
    "        splitter = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=42)\n",
    "        train_idx, test_idx = next(splitter.split(X, y, groups=groups))\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        groups_train = groups[train_idx]  # Extract corresponding train groups\n",
    "\n",
    "        if debug:\n",
    "            print(f\"Columns in X_Train: {X_train.columns}\")\n",
    "            print(f\"Columns in X_Test: {X_test.columns}\")\n",
    "\n",
    "        return X_train, X_test, y_train, y_test, groups_train\n",
    "\n",
    "\n",
    "\n",
    "def Optimize_Model(X_train,y_train,groups_train,debug=False,raw=False,soft_label=False,pkl_name = 'grid_search'):\n",
    "    '''This section will take the selected model in 'params' and train the model'''\n",
    "\n",
    "    kf = GroupKFold(n_splits=5)\n",
    "    if soft_label == True and raw == True:\n",
    "        # Define parameter grids\n",
    "        pipeline = Pipeline([\n",
    "            ('regressor', RandomForestRegressor())  # Placeholder\n",
    "        ])\n",
    "        param_grid = [\n",
    "            {  # Random Forest Regressor\n",
    "                'regressor': [RandomForestRegressor(random_state=42)],\n",
    "                'regressor__n_estimators': [50, 100, 200],\n",
    "                'regressor__max_depth': [10, 20, None],\n",
    "                'regressor__min_samples_split': [2, 5, 10]\n",
    "            },\n",
    "            {  # XGBoost Regressor\n",
    "                'regressor': [XGBRegressor(objective='reg:squarederror', random_state=42)],\n",
    "                'regressor__n_estimators': [50, 100, 200],\n",
    "                'regressor__max_depth': [3, 6, 10],\n",
    "                'regressor__learning_rate': [0.01, 0.1, 0.2]\n",
    "            },\n",
    "            {  # Vanilla Linear Regression (no tuning)\n",
    "                'regressor': [LinearRegression()]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Set up GridSearchCV\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=param_grid,\n",
    "            scoring='neg_mean_squared_error',  # works for both regressors and log-loss classifiers\n",
    "            cv=kf,\n",
    "            n_jobs=-1,\n",
    "            verbose=3\n",
    "        )\n",
    "\n",
    "        grid_search.fit(X_train, y_train, groups=groups_train)\n",
    "\n",
    "        with open(f'{pkl_name}.pkl', 'wb') as f:\n",
    "            pickle.dump(grid_search, f)\n",
    "\n",
    "        if debug:\n",
    "            from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "            best_model = grid_search.best_estimator_  # or gs_xgb.best_estimator_\n",
    "            y_pred = best_model.predict(X_train)\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.scatter(y_train, y_pred, alpha=0.4, s=10)\n",
    "            plt.plot([0, 1], [0, 1], 'r--', label=\"Perfect Prediction\")\n",
    "            plt.xlabel(\"True Soft Label\")\n",
    "            plt.ylabel(\"Predicted Soft Label\")\n",
    "            plt.title(f\"Model – Soft Label Prediction Accuracy (Training)\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "        return grid_search\n",
    "\n",
    "    if raw == True:\n",
    "        # Define parameter grids\n",
    "        pipeline = Pipeline([\n",
    "            ('regressor', RandomForestRegressor())  # Placeholder\n",
    "        ])\n",
    "        param_grid = [\n",
    "            {  # Random Forest Regressor\n",
    "                'regressor': [RandomForestRegressor(random_state=42)],\n",
    "                'regressor__n_estimators': [50, 100, 200],\n",
    "                'regressor__max_depth': [10, 20, None],\n",
    "                'regressor__min_samples_split': [2, 5, 10]\n",
    "            },\n",
    "            {  # XGBoost Regressor\n",
    "                'regressor': [XGBRegressor(objective='reg:squarederror', random_state=42)],\n",
    "                'regressor__n_estimators': [50, 100, 200],\n",
    "                'regressor__max_depth': [3, 6, 10],\n",
    "                'regressor__learning_rate': [0.01, 0.1, 0.2]\n",
    "            },\n",
    "            {  # Vanilla Linear Regression (no tuning)\n",
    "                'regressor': [LinearRegression()]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Set up GridSearchCV\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=param_grid,\n",
    "            scoring='neg_mean_squared_error',  # works for both regressors and log-loss classifiers\n",
    "            cv=kf,\n",
    "            n_jobs=-1,\n",
    "            verbose=3\n",
    "        )\n",
    "\n",
    "        grid_search.fit(X_train, y_train, groups=groups_train)\n",
    "\n",
    "        with open('best_grid_search_raw_mixed.pkl', 'wb') as f:\n",
    "            pickle.dump(grid_search, f)\n",
    "\n",
    "        if debug:\n",
    "            from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "            # Predict on training data\n",
    "            y_train_pred = grid_search.best_estimator_.predict(X_train)\n",
    "\n",
    "            # Calculate metrics\n",
    "            mse = mean_squared_error(y_train, y_train_pred)\n",
    "            mae = mean_absolute_error(y_train, y_train_pred)\n",
    "            r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "            print(f\"Training MSE: {mse:.4f}\")\n",
    "            print(f\"Training MAE: {mae:.4f}\")\n",
    "            print(f\"Training R^2: {r2:.4f}\")\n",
    "\n",
    "            # Scatter plot: Predicted vs Actual\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.scatter(y_train, y_train_pred, alpha=0.6)\n",
    "            plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "            plt.xlabel(\"Actual Values\")\n",
    "            plt.ylabel(\"Predicted Values\")\n",
    "            plt.title(\"Predicted vs Actual (Training Data)\")\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "            # Residual plot: Residuals vs Predicted\n",
    "            residuals = y_train - y_train_pred\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.scatter(y_train_pred, residuals, alpha=0.6)\n",
    "            plt.hlines(0, y_train_pred.min(), y_train_pred.max(), colors='r', linestyles='dashed')\n",
    "            plt.xlabel(\"Predicted Values\")\n",
    "            plt.ylabel(\"Residuals (Actual - Predicted)\")\n",
    "            plt.title(\"Residual Plot (Training Data)\")\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "        return grid_search\n",
    "\n",
    "    if raw == False: #Case: classification problem\n",
    "        pipeline = Pipeline([\n",
    "            ('classifier', RandomForestClassifier(random_state=42))  # Placeholder, will be overridden\n",
    "        ])\n",
    "        # Define parameter grids for different classifiers\n",
    "        param_grid = [\n",
    "            {  # Random Forest\n",
    "                'classifier': [RandomForestClassifier(random_state=42)],\n",
    "                'classifier__n_estimators': [50, 100, 200],\n",
    "                'classifier__max_depth': [10, 20, None],\n",
    "                'classifier__min_samples_split': [2, 5, 10]\n",
    "            },\n",
    "            {  # XGBoost\n",
    "                'classifier': [XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)],\n",
    "                'classifier__n_estimators': [50, 100, 200],\n",
    "                'classifier__max_depth': [3, 6, 10],\n",
    "                'classifier__learning_rate': [0.01, 0.1, 0.2]\n",
    "            },\n",
    "            # {  # Logistic Regression\n",
    "            #     'classifier': [LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)],\n",
    "            #     'classifier__C': [0.01, 0.1, 1, 10],\n",
    "            #     'classifier__penalty': ['l2']\n",
    "            # },\n",
    "            {  # Vanilla Logistic Regression (no hyperparameter tuning)\n",
    "                'classifier': [LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)]\n",
    "                # No hyperparameters specified\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Perform GridSearchCV with GroupKFold\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=param_grid,\n",
    "            scoring='f1_micro',\n",
    "            cv=kf,\n",
    "            n_jobs=-1,\n",
    "            verbose=3\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train, groups=groups_train)\n",
    "        with open('best_grid_search_10_bins_percentiles.pkl', 'wb') as f:\n",
    "            pickle.dump(grid_search, f)\n",
    "\n",
    "        if debug:\n",
    "\n",
    "            y_pred = grid_search.best_estimator_.predict(X_train)\n",
    "            # Extract the classifier name from the pipeline\n",
    "            model_name = grid_search.best_estimator_.named_steps['classifier'].__class__.__name__\n",
    "\n",
    "            # Plot confusion matrix\n",
    "            fig, ax = plt.subplots(figsize=(6, 5))\n",
    "            ConfusionMatrixDisplay.from_predictions(y_train, y_pred, ax=ax)\n",
    "            ax.set_title(f\"Training Data Confusion Matrix {model_name}\")\n",
    "            plt.show()\n",
    "        return grid_search\n",
    "\n",
    "\n",
    "\n",
    "def bootstrap_roc_auc(y_true, y_score, n_bootstraps=1000, random_state=42):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    tprs = []\n",
    "    base_fpr = np.linspace(0, 1, 101)\n",
    "    y_true = np.array(y_true)\n",
    "    y_score = np.array(y_score)\n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = rng.choice(len(y_true), size=len(y_true), replace=True)\n",
    "        # if len(np.unique(y_true[indices])) < 2:\n",
    "        #     continue  # skip if only one class present\n",
    "        fpr, tpr, _ = roc_curve(y_true[indices], y_score[indices])\n",
    "        tpr_interp = np.interp(base_fpr, fpr, tpr)\n",
    "        tpr_interp[0] = 0.0\n",
    "        tprs.append(tpr_interp)\n",
    "\n",
    "    tprs = np.array(tprs)\n",
    "    mean_tpr = tprs.mean(axis=0)\n",
    "    std_tpr = tprs.std(axis=0)\n",
    "    tprs_lower = np.clip(mean_tpr - 1.96 * std_tpr, 0, 1)\n",
    "    print(tprs_lower)\n",
    "    tprs_upper = np.clip(mean_tpr + 1.96 * std_tpr, 0, 1)\n",
    "\n",
    "    return base_fpr, mean_tpr, tprs_lower, tprs_upper\n",
    "def run_visualizations(grid_search,X_test,y_test,bin_threshold,raw=False,label='Default'):\n",
    "    if raw == False:\n",
    "        best_models = {}\n",
    "        model_performance = []\n",
    "\n",
    "\n",
    "\n",
    "        for i, param in enumerate(grid_search.cv_results_['params']):\n",
    "            model_name = param['classifier'].__class__.__name__\n",
    "            mean_score = grid_search.cv_results_['mean_test_score'][i]\n",
    "\n",
    "            # Only store the best param set per model\n",
    "            if model_name not in best_models or mean_score > best_models[model_name]['score']:\n",
    "                best_models[model_name] = {\n",
    "                    'params': param,\n",
    "                    'score': mean_score\n",
    "                }\n",
    "\n",
    "        # Refit the best model for each model type\n",
    "        for model_name in best_models:\n",
    "            best_param = best_models[model_name]['params']\n",
    "            model_pipeline = grid_search.estimator.set_params(**best_param)\n",
    "            model_pipeline.fit(X_test, y_test)\n",
    "            classifier = model_pipeline.named_steps['classifier']\n",
    "            best_models[model_name]['model'] = classifier  # Store fitted classifier\n",
    "\n",
    "        for model_name, model_info in best_models.items():\n",
    "            best_model = model_info['model']\n",
    "            print(f\"Running model: {model_name}\")\n",
    "            y_true_binary = (y_test <= bin_threshold).astype(int)\n",
    "            y_pred_prob = best_model.predict_proba(X_test)  #Outputs an array of probabilities for each test data corresponding to the ten categories\n",
    "            # Classes to sum for binary prob\n",
    "            pred_prob_below_thresh = y_pred_prob[:, :bin_threshold].sum(axis=1)\n",
    "            y_pred_prob_binary = (pred_prob_below_thresh >= 0.5).astype(int) #We classify as \"1\" if your probability is >=.5\n",
    "            # Compute ROC curve and AUC\n",
    "            fpr, tpr, _ = roc_curve(y_true_binary, y_pred_prob_binary)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.close('all')\n",
    "            plt.figure()\n",
    "            # Plot the ROC curve\n",
    "            plt.plot(fpr, tpr, label=f\"{model_name} (AUC = {roc_auc:.3f})\")\n",
    "            plt.xlabel(\"False Positive Rate\")\n",
    "            plt.ylabel(\"True Positive Rate\")\n",
    "            plt.title(f\"ROC AUC Curve (Threshold = {bin_threshold})\")\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"{label}-AUC.png\")\n",
    "\n",
    "            # Bootstrap ROC and get confidence bounds\n",
    "            fpr,tpr, tpr_lower, tpr_upper = bootstrap_roc_auc(\n",
    "                y_true_binary, y_pred_prob_binary\n",
    "            )\n",
    "            # Compute AUC for the lower bound of the TPR\n",
    "            auc_lower_bound = auc(fpr, tpr_lower)\n",
    "\n",
    "            # Compute AUC for the upper bound of the TPR\n",
    "            auc_upper_bound = auc(fpr, tpr_upper)\n",
    "\n",
    "\n",
    "            tn,fp,fn,tp = confusion_matrix(y_true_binary,y_pred_prob_binary).ravel() #Ravel flattens this into a 1d Array so we can assign the variables\n",
    "            sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0  # same as recall\n",
    "            specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "            precision = precision_score(y_true_binary, y_pred_prob_binary, zero_division=0)\n",
    "            recall = recall_score(y_true_binary, y_pred_prob_binary, zero_division=0)\n",
    "            f1 = f1_score(y_true_binary, y_pred_prob_binary, zero_division=0)\n",
    "\n",
    "\n",
    "            # roc_auc = auc(fpr, mean_tpr)\n",
    "            # plt.plot(fpr, mean_tpr, label=f\"{model_name} (AUC = {roc_auc:.3f})\")\n",
    "            plt.fill_between(fpr, tpr_lower, tpr_upper, alpha=0.2)\n",
    "            model_performance.append({\n",
    "                'Model': model_name,\n",
    "                'AUC': roc_auc,\n",
    "                'CI Lower Bound': auc_lower_bound,\n",
    "                'CI Upper Bound': auc_upper_bound,\n",
    "                'Sensitivity': sensitivity,\n",
    "                'Specificity': specificity,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'F1 Score': f1\n",
    "            })\n",
    "\n",
    "        # Final plot settings\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC AUC Curve with 95% CI\")\n",
    "        plt.legend()\n",
    "        plt.plot([0, 1], [0, 1], 'k--', label=\"Chance (AUC = 0.5)\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        performance_df = pd.DataFrame(model_performance)\n",
    "        # Display the table of AUC and CI for each model\n",
    "        performance_df.to_excel(f\"performance-{label}.xlsx\")\n",
    "\n",
    "        ##Calibration curves\n",
    "        # plt.figure(figsize=(8, 6))\n",
    "\n",
    "        # Set up subplot grid\n",
    "        num_models = len(best_models)\n",
    "        ncols = 2\n",
    "        nrows = (num_models + 1) // ncols  # Round up for uneven count\n",
    "        fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 4 * nrows))\n",
    "        axes = axes.flatten()  # Flatten to index easily\n",
    "\n",
    "        for idx, (model_name, model_info) in enumerate(best_models.items()):\n",
    "            ax = axes[idx]\n",
    "            best_model = model_info['model']\n",
    "            print(f\"Running model: {model_name}\")\n",
    "\n",
    "            y_true_binary = (y_test <= bin_threshold).astype(int)\n",
    "            y_pred_prob = best_model.predict_proba(X_test)\n",
    "            pred_prob_below_thresh = y_pred_prob[:, :bin_threshold].sum(axis=1)\n",
    "\n",
    "            fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "                y_true_binary, pred_prob_below_thresh, n_bins=10\n",
    "            )\n",
    "\n",
    "            # Plot calibration curve\n",
    "            ax.plot(mean_predicted_value, fraction_of_positives, marker='o', label='Calibration Curve')\n",
    "\n",
    "            # Plot histogram for RandomForest\n",
    "            # if \"Random\" in model_name:\n",
    "            counts, bins = np.histogram(pred_prob_below_thresh, bins=10, range=(0, 1))\n",
    "            proportions = counts / counts.sum()\n",
    "            bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "            bin_width = bins[1] - bins[0]\n",
    "            ax.bar(bin_centers, proportions, width=bin_width, alpha=0.5, label='Pred Prob Histogram')\n",
    "            ax.set_ylim(0, 1)\n",
    "\n",
    "            # Perfect calibration line\n",
    "            ax.plot([0, 1], [0, 1], 'k--', label='Perfectly Calibrated')\n",
    "\n",
    "            ax.set_title(f\"{model_name} Calibration\")\n",
    "            ax.set_xlabel(\"Mean Predicted Probability\")\n",
    "            ax.set_ylabel(\"Fraction of Positives\")\n",
    "            # ax.legend(loc='best')\n",
    "            ax.grid(True)\n",
    "\n",
    "        # Hide any unused subplots\n",
    "        for j in range(idx + 1, len(axes)):\n",
    "            fig.delaxes(axes[j])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def sixty_sixty_predictions(X_test):\n",
    "    y_pred = []\n",
    "\n",
    "    for index, row in X_test.iterrows():\n",
    "        hz_500 = row[\"hz500\"]\n",
    "        hz_1000 = row[\"hz1000\"]\n",
    "        hz_2000 = row[\"hz2000\"]\n",
    "        wrs = row[\"WRS\"]\n",
    "\n",
    "        if hz_500 >= 60 and hz_1000 >= 60 and hz_2000 >= 60 and wrs < 60:\n",
    "            y_pred.append(1) #They are a candidate\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def soft_label(y, center=40, sharpness=15):\n",
    "    \"\"\"Smoothly map scores to probabilities that y <= center.\"\"\"\n",
    "    return 1 / (1 + np.exp((y - center) / sharpness))\n",
    "\n",
    "\n",
    "def different_variables_run():\n",
    "    ##Run 1\n",
    "\n",
    "    set_dict = {\n",
    "        \"ag-only\":\n",
    "        #Audiogram Only\n",
    "        [\n",
    "        'hz125_R', 'hz125_L', 'hz250_R', 'hz250_L',\n",
    "        'hz500_R', 'hz500_L', 'hz750_R', 'hz750_L',\n",
    "        'hz1000_R', 'hz1000_L', 'hz1500_R', 'hz1500_L',\n",
    "        'hz2000_R', 'hz2000_L', 'hz3000_R', 'hz3000_L',\n",
    "        'hz4000_R', 'hz4000_L', 'hz6000_R', 'hz6000_L', 'hz8000_R', 'hz8000_L', 'CNC_L', 'CNC_R'\n",
    "        ],\n",
    "        \"wrs\":\n",
    "        #audiogram + WRS\n",
    "        [\n",
    "        'hz125_R', 'hz125_L', 'hz250_R', 'hz250_L',\n",
    "        'hz500_R', 'hz500_L', 'hz750_R', 'hz750_L',\n",
    "        'hz1000_R', 'hz1000_L', 'hz1500_R', 'hz1500_L',\n",
    "        'hz2000_R', 'hz2000_L', 'hz3000_R', 'hz3000_L',\n",
    "        'hz4000_R', 'hz4000_L', 'hz6000_R', 'hz6000_L', 'hz8000_R', 'hz8000_L',\n",
    "        'WRS_L', 'WRS_R', 'CNC_L', 'CNC_R'\n",
    "        ],\n",
    "        \"wrs-a\":\n",
    "\n",
    "        #Audiogram + WRS + Age\n",
    "        [\n",
    "        'hz125_R', 'hz125_L', 'hz250_R', 'hz250_L',\n",
    "        'hz500_R', 'hz500_L', 'hz750_R', 'hz750_L',\n",
    "        'hz1000_R', 'hz1000_L', 'hz1500_R', 'hz1500_L',\n",
    "        'hz2000_R', 'hz2000_L', 'hz3000_R', 'hz3000_L',\n",
    "        'hz4000_R', 'hz4000_L', 'hz6000_R', 'hz6000_L', 'hz8000_R', 'hz8000_L',\n",
    "        'WRS_L', 'WRS_R', 'Age','CNC_L', 'CNC_R'\n",
    "        ],\n",
    "        # #TODO: Audiogram + WRS + Age + Duration HL\n",
    "        # \"wrs-a-dhl\":\n",
    "        #\n",
    "        #     [\n",
    "        # 'hz125_R', 'hz125_L', 'hz250_R', 'hz250_L',\n",
    "        # 'hz500_R', 'hz500_L', 'hz750_R', 'hz750_L',\n",
    "        # 'hz1000_R', 'hz1000_L', 'hz1500_R', 'hz1500_L',\n",
    "        # 'hz2000_R', 'hz2000_L', 'hz3000_R', 'hz3000_L',\n",
    "        # 'hz4000_R', 'hz4000_L', 'hz6000_R', 'hz6000_L', 'hz8000_R', 'hz8000_L',\n",
    "        # 'WRS_L', 'WRS_R', 'Age', 'CNC_L', 'CNC_R'\n",
    "        # ],\n",
    "        # \"wrs-a-dhl-dha\":\n",
    "        # #TODO:Audiogram + WRS + Age + Duration HL + Duration HA Usage\n",
    "        # [\n",
    "        #     'hz125_R', 'hz125_L', 'hz250_R', 'hz250_L',\n",
    "        #     'hz500_R', 'hz500_L', 'hz750_R', 'hz750_L',\n",
    "        #     'hz1000_R', 'hz1000_L', 'hz1500_R', 'hz1500_L',\n",
    "        #     'hz2000_R', 'hz2000_L', 'hz3000_R', 'hz3000_L',\n",
    "        #     'hz4000_R', 'hz4000_L', 'hz6000_R', 'hz6000_L', 'hz8000_R', 'hz8000_L',\n",
    "        #     'WRS_L', 'WRS_R', 'Age', 'CNC_L', 'CNC_R'\n",
    "        # ]\n",
    "\n",
    "    }\n",
    "\n",
    "    for key, value in tqdm(set_dict.items(), desc=\"Processing sets\"):\n",
    "        label = key\n",
    "        all_labels = value\n",
    "        main_ml_call(\n",
    "            num_bins=10,\n",
    "            smote=False,\n",
    "            method=\"ML\",\n",
    "            raw=False,\n",
    "            is_soft_label=False,\n",
    "            all_labels=all_labels,\n",
    "            label=label\n",
    "        )\n",
    "\n",
    "\n",
    "def sixty_sixty_run():\n",
    "    all_labels = [\n",
    "        'hz125_R', 'hz125_L', 'hz250_R', 'hz250_L',\n",
    "        'hz500_R', 'hz500_L', 'hz750_R', 'hz750_L',\n",
    "        'hz1000_R', 'hz1000_L', 'hz1500_R', 'hz1500_L',\n",
    "        'hz2000_R', 'hz2000_L', 'hz3000_R', 'hz3000_L',\n",
    "        'hz4000_R', 'hz4000_L', 'hz6000_R', 'hz6000_L', 'hz8000_R', 'hz8000_L',\n",
    "        'WRS_L', 'WRS_R', 'Age', 'CNC_L', 'CNC_R'\n",
    "    ]\n",
    "\n",
    "    main_ml_call(method=\"60/60\",label=\"sixty\",all_labels=all_labels)\n",
    "\n",
    "def main_ml_call(num_bins = 10, smote = False, method = \"ML\",raw=False,is_soft_label = False,all_labels = [],label = 'default'):\n",
    "\n",
    "    #############################\n",
    "    #Extract columns of interest, remove NA, and add patient ID and CNC bin\n",
    "    filtered_dataset = Clean_Data(debug=False,all_labels=all_labels)\n",
    "    left_right_data = Create_Left_Right_Data(filtered_dataset,debug=False)\n",
    "    if raw == True:\n",
    "        X_train, X_test, y_train,y_test,groups_train = Train_Test_Split(left_right_data, debug=False,raw=True)\n",
    "        if method == \"ML\":\n",
    "            #Run grid search on the split data **for regressor**\n",
    "\n",
    "            if is_soft_label:\n",
    "                y_train_soft = soft_label(y_train)\n",
    "                x = np.linspace(0,1,len(y_train_soft))\n",
    "                plt.scatter(x,y_train_soft)\n",
    "                plt.show()\n",
    "                y_test_soft = soft_label(y_test)\n",
    "\n",
    "                # # Hard binary label for evaluation only\n",
    "                # y_train_binary = (y_train <= 40).astype(int)\n",
    "                # y_test_binary = (y_test <= 40).astype(int)\n",
    "                grid_search = Optimize_Model(X_train, y_train_soft, groups_train, debug=True, raw=True,soft_label=is_soft_label,pkl_name=label)\n",
    "\n",
    "            else:\n",
    "                # grid_search = Optimize_Model(X_train, y_train, groups_train, debug=True, raw=True)\n",
    "\n",
    "                with open(f'{label}.pkl', 'rb') as f:\n",
    "                    grid_search = pickle.load(f)\n",
    "\n",
    "                #Make y_train and y_test binary now\n",
    "                y_train_binary = (y_train <=40).astype(int) #A series of 0/1\n",
    "                y_test_binary = (y_test <=40).astype(int)\n",
    "\n",
    "                best_model = grid_search.best_estimator_\n",
    "                print(best_model)\n",
    "                y_pred = best_model.predict(X_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # run_visualizations(grid_search, X_test, y_test,bin_threshold=fifty_threshold)\n",
    "\n",
    "            #\n",
    "            # y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "            # model_name = grid_search.best_estimator_.named_steps['classifier'].__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    if raw == False:\n",
    "        binned_data,fifty_threshold = Add_Categorical_Bins(left_right_data,num_bins=10,debug=False)\n",
    "\n",
    "    # Split into train/test while preserving which patient is in each group\n",
    "        X_train, X_test, y_train,y_test,groups_train = Train_Test_Split(binned_data, debug=False,raw=False)\n",
    "\n",
    "        if smote:\n",
    "            #Equal *spaced* bins with SMOTE applied\n",
    "            smote = SMOTE(sampling_strategy=\"auto\", random_state=42)\n",
    "            X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "            plt.hist(y_train_resampled, edgecolor='black', alpha=0.7)\n",
    "            # Extend `groups_train` to match SMOTE's new sample count\n",
    "            num_new_samples = len(X_train_resampled) - len(X_train)\n",
    "            # Assign synthetic samples a placeholder group (-1)\n",
    "            groups_resampled = np.concatenate([groups_train, np.full(num_new_samples, -1)])\n",
    "            X_train, y_train, groups_train = X_train_resampled, y_train_resampled, groups_resampled\n",
    "\n",
    "        if method == \"ML\":\n",
    "            #Run grid search on the split data **for multicategorical classifier**\n",
    "            grid_search = Optimize_Model(X_train,y_train,groups_train,debug=True)\n",
    "            # with open('best_grid_search_10_bins_smote.pkl', 'rb') as f:\n",
    "            #     grid_search = pickle.load(f)\n",
    "\n",
    "\n",
    "            #Sanity check our best model with a confusion matrix on X_test\n",
    "            y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "            model_name = grid_search.best_estimator_.named_steps['classifier'].__class__.__name__\n",
    "            fig, ax = plt.subplots(figsize=(6, 5))\n",
    "            ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax)\n",
    "            ax.set_title(f\"Best Model ({model_name}) on Test Data for {label}\")\n",
    "            plt.savefig(f\"cm-{label}\")\n",
    "            # plt.show()\n",
    "\n",
    "\n",
    "            run_visualizations(grid_search, X_test, y_test,bin_threshold=fifty_threshold,label=label)\n",
    "        if method == \"60/60\":\n",
    "            # Get predictions\n",
    "            y_pred = sixty_sixty_predictions(X_test)\n",
    "            y_true_binary = (y_test <= 5).astype(int)\n",
    "\n",
    "            # Accuracy\n",
    "            accuracy = accuracy_score(y_true_binary, y_pred)\n",
    "            print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "            # Confusion Matrix\n",
    "            conf_matrix = confusion_matrix(y_true_binary, y_pred)\n",
    "            print(\"Confusion Matrix:\")\n",
    "            print(conf_matrix)\n",
    "\n",
    "            # Plot confusion matrix\n",
    "            # plt.figure(figsize=(6, 5))\n",
    "            # sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "            #             xticklabels=[\"Predicted Non-Candidate\", \"Predicted Candidate\"],\n",
    "            #             yticklabels=[\"Actual Non-Candidate\", \"Actual Candidate\"])\n",
    "            # plt.xlabel(\"Prediction\")\n",
    "            # plt.ylabel(\"Actual\")\n",
    "            # plt.title(\"Confusion Matrix\")\n",
    "            # plt.tight_layout()\n",
    "            # plt.show()\n",
    "            y_true_binary = y_true_binary.values.tolist()\n",
    "            print(y_true_binary)\n",
    "            print(y_pred)\n",
    "\n",
    "            precision = precision_score(y_true_binary, y_pred, zero_division=0)\n",
    "            recall = recall_score(y_true_binary, y_pred, zero_division=0)\n",
    "            f1 = f1_score(y_true_binary, y_pred, zero_division=0)\n",
    "\n",
    "            print(f\"Precision: {precision}, Recall: {recall}, F1: {recall}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95a332a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_feature_sets_with_pycaret(X_train, y_train, groups_train, feature_sets, session_id=123, n_splits=5):\n",
    "    results = []\n",
    "\n",
    "    for i, features in enumerate(feature_sets):\n",
    "        print(f\"\\n▶️ Testing feature set {i+1}/{len(feature_sets)}: {features}\")\n",
    "        \n",
    "        # Prepare training data for PyCaret\n",
    "        df = X_train[features].copy()\n",
    "        df['target'] = y_train.values\n",
    "\n",
    "        # Create GroupKFold strategy\n",
    "        gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "        # Run PyCaret setup\n",
    "        try:\n",
    "            setup(\n",
    "                data=df,\n",
    "                target='target',\n",
    "                fold_strategy=gkf,\n",
    "                fold_groups=groups_train,\n",
    "                session_id=session_id,\n",
    "                silent=True,\n",
    "                verbose=False,\n",
    "                use_gpu=False\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Setup failed for feature set {features}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Compare models and get results\n",
    "        try:\n",
    "            best_model = compare_models()\n",
    "            comparison_df = pull()  # Pull performance table\n",
    "            \n",
    "            top_row = comparison_df.iloc[0]  # Best model metrics\n",
    "\n",
    "            results.append({\n",
    "                'features': features,\n",
    "                'model': top_row['Model'],\n",
    "                'Accuracy': top_row['Accuracy'],\n",
    "                'AUC': top_row.get('AUC'),\n",
    "                'F1': top_row.get('F1'),\n",
    "                'Recall': top_row.get('Recall'),\n",
    "                'Precision': top_row.get('Prec.')\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Model comparison failed for feature set {features}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2107b981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing before: 83\n",
      "Missing after: 0\n",
      "Index(['hz125', 'hz250', 'hz500', 'hz750', 'hz1000', 'hz1500', 'hz2000',\n",
      "       'hz3000', 'hz4000', 'hz6000', 'hz8000', 'WRS', 'HLdur', 'Age'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Full dataset with all additions\n",
    "all_labels = [\n",
    "        'hz125_R', 'hz125_L', 'hz250_R', 'hz250_L',\n",
    "        'hz500_R', 'hz500_L', 'hz750_R', 'hz750_L',\n",
    "        'hz1000_R', 'hz1000_L', 'hz1500_R', 'hz1500_L',\n",
    "        'hz2000_R', 'hz2000_L', 'hz3000_R', 'hz3000_L',\n",
    "        'hz4000_R', 'hz4000_L', 'hz6000_R', 'hz6000_L', 'hz8000_R', 'hz8000_L',\n",
    "        'WRS_L', 'WRS_R', 'Age','HLdur_R','HLdur_L','Hearing_Aid_Use_Time_R','Hearing_Aid_Use_Time_R','CNC_L', 'CNC_R',\n",
    "        ]\n",
    "\n",
    "filtered_dataset = Clean_Data(debug=False,all_labels=all_labels)\n",
    "left_right_data = Create_Left_Right_Data(filtered_dataset,debug=False)\n",
    "X_train, X_test, y_train,y_test,groups_train = Train_Test_Split(left_right_data, debug=False,raw=True)\n",
    "\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7705fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature sets \n",
    "\n",
    "feature_sets = [\n",
    "        #Audiogram Only\n",
    "        [\n",
    "        'hz125_R', 'hz125_L', 'hz250_R', 'hz250_L',\n",
    "        'hz500_R', 'hz500_L', 'hz750_R', 'hz750_L',\n",
    "        'hz1000_R', 'hz1000_L', 'hz1500_R', 'hz1500_L',\n",
    "        'hz2000_R', 'hz2000_L', 'hz3000_R', 'hz3000_L',\n",
    "        'hz4000_R', 'hz4000_L', 'hz6000_R', 'hz6000_L', 'hz8000_R', 'hz8000_L'\n",
    "        ],\n",
    "        #audiogram + WRS\n",
    "        [\n",
    "        'hz125_R', 'hz125_L', 'hz250_R', 'hz250_L',\n",
    "        'hz500_R', 'hz500_L', 'hz750_R', 'hz750_L',\n",
    "        'hz1000_R', 'hz1000_L', 'hz1500_R', 'hz1500_L',\n",
    "        'hz2000_R', 'hz2000_L', 'hz3000_R', 'hz3000_L',\n",
    "        'hz4000_R', 'hz4000_L', 'hz6000_R', 'hz6000_L', 'hz8000_R', 'hz8000_L',\n",
    "        'WRS_L', 'WRS_R'\n",
    "        ],\n",
    "        #Audiogram + WRS + Age\n",
    "        [\n",
    "        'hz125_R', 'hz125_L', 'hz250_R', 'hz250_L',\n",
    "        'hz500_R', 'hz500_L', 'hz750_R', 'hz750_L',\n",
    "        'hz1000_R', 'hz1000_L', 'hz1500_R', 'hz1500_L',\n",
    "        'hz2000_R', 'hz2000_L', 'hz3000_R', 'hz3000_L',\n",
    "        'hz4000_R', 'hz4000_L', 'hz6000_R', 'hz6000_L', 'hz8000_R', 'hz8000_L',\n",
    "        'WRS_L', 'WRS_R', 'Age'\n",
    "        ],\n",
    "     #Audiogram + WRS + Age + HL Duration\n",
    "        [\n",
    "        'hz125_R', 'hz125_L', 'hz250_R', 'hz250_L',\n",
    "        'hz500_R', 'hz500_L', 'hz750_R', 'hz750_L',\n",
    "        'hz1000_R', 'hz1000_L', 'hz1500_R', 'hz1500_L',\n",
    "        'hz2000_R', 'hz2000_L', 'hz3000_R', 'hz3000_L',\n",
    "        'hz4000_R', 'hz4000_L', 'hz6000_R', 'hz6000_L', 'hz8000_R', 'hz8000_L',\n",
    "        'WRS_L', 'WRS_R', 'Age','HLdur_R','HLdur_L'\n",
    "        ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
